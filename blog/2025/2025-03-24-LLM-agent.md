# LLM을 이용해서 agent를 만들어보기 위한 지식 정리

## LLM을 이용해서 agent를 만들어보기 위한 기초 지식 정리

## 1. 들어가며

최근 대규모 언어 모델(LLM, Large Language Model)이 주목받으면서, LLM을 기반으로 한 에이전트(Agent)를 구현하려는 시도가 활발하다. 에이전트는 자연어 입력을 받고 이에 따라 직접 사고 과정을 거쳐 실행, 행동 등을 수행하는 독립적인 시스템을 말한다. 본 글에서는 LLM을 이용해 에이전트를 만들어보기 위한 기초적인 개념과 기술들을 간단히 정리해보려고 한다.

<!-- truncate -->

## 2. LLM이란?

LLM(Large Language Model)은 대규모 텍스트 데이터를 학습하여, 문맥을 이해하고 새로운 텍스트를 생성할 수 있는 모델이다. GPT 시리즈를 비롯한 다양한 모델들이 존재한다. 최근에는 훈련 파라미터의 수가 수십억 단위를 넘어서는 모델이 주류가 되고 있으며, 이들은 다음과 같은 특징을 가진다.

1. **문맥 이해 능력**: 긴 문장이나 문서 내에서 맥락을 파악하고, 적절한 답변이나 요약을 생성.
2. **다양한 태스크 수행**: 질의응답, 요약, 번역, 생성, 대화 등 광범위한 자연어 처리(NLP) 과제에 활용 가능.
3. **파인튜닝 용이**: 프롬프트 엔지니어링(Prompt Engineering) 또는 적은 양의 추가 데이터로 원하는 작업에 대한 성능을 향상할 수 있음.

---

## 3. 에이전트(Agent)란 무엇인가?

에이전트는 특정 목표를 달성하기 위해 주변 환경을 관찰하고, 학습하며, 행동하는 자율적인 시스템이다. LLM 기반 에이전트는 텍스트 입력을 받아 특정 목적을 달성하기 위한 추론 및 행동 과정을 텍스트 기반으로 수행한다.  
다음과 같은 프로세스로 동작하는 사례가 많다.

1. **Goal 설정**: 에이전트가 수행해야 할 작업 혹은 질문.
2. **Observation (환경 인식)**: 현재 대화나 입력된 텍스트, 이전 상태 등을 바탕으로 상황을 분석.
3. **Thinking (추론 과정)**: LLM을 통해 문제 해결에 필요한 아이디어나 접근법을 생각.
4. **Action (행동)**: 필요한 경우 외부 툴 혹은 API와 연동하여 행동을 실행하거나, 결과를 요약하여 사용자에게 반환.

---

## 4. LLM 에이전트 구현을 위한 주요 개념

### 4.1 프롬프트 엔지니어링(Prompt Engineering)

에이전트가 LLM으로부터 원하는 결과를 얻으려면 적절한 프롬프트를 작성해야 한다.

- **Context 설정**: 에이전트의 역할, 목표, 제약사항 등을 명시적으로 알려주어야 한다.
- **Few-Shot 예시 제공**: 원하는 출력 형식과 예시를 짧게나마 제공해 에이전트가 어떻게 답변해야 하는지 힌트를 줄 수 있다.

### 4.2 체인(Chain) 구성

주어진 목표를 달성하기 위해 여러 단계를 거쳐야 할 수 있는데, 이때 각 단계별로 LLM의 출력을 입력으로 삼아 다음 단계를 수행하도록 연결하는 방법을 체인으로 부른다.

- **LangChain** 등과 같은 라이브러리를 활용하면 체인 구성을 단순화할 수 있다.
- 여러 개의 프롬프트(혹은 태스크)를 순차적으로 호출하거나, 가중치나 조건에 따라 분기 처리가 가능하다.

### 4.3 툴(Functions, API) 연동

LLM 기반 에이전트가 단순히 텍스트를 생성하는 것만으로 끝나지 않도록, 실제 환경과 상호작용하기 위한 툴 연동이 필요하다.

- **예시**: 데이터베이스 조회, 검색 엔진, 서드파티 API 호출, 계산 기능 등.
- LLM 출력(텍스트)에서 ‘이제 어떤 행동을 취할 것인지’를 결정하고, 해당 행동을 외부 함수나 API로 연결해주는 인터페이스를 마련해야 한다.

### 4.4 메모리(Memory)

에이전트는 이전 대화나 상태, 행동의 결과 등을 기억해야 보다 지능적인 행동을 할 수 있다.

- **짧은 맥락 관리(Short-Term Memory)**: 이전 몇 문장 정도의 대화 히스토리만 저장하는 방식.
- **긴 문맥 관리(Long-Term Memory)**: 요약 저장, 벡터 DB, 혹은 문서 임베딩을 통해 중요한 정보와 함께 장기적으로 기억해 활용.

---

## 5. 간단한 구현 절차 예시

1. **모델 선택**: 원하는 모델 LLM을 정하고, 모델이 제공하는 API나 라이브러리를 준비.
2. **목적 설정**: 에이전트에게 “사용자의 질의에 맞춰 데이터베이스에서 답변을 추출하라”와 같은 목적을 명확히 부여.
3. **프롬프트 설계**: 에이전트의 성격, 목표, 권장 답변 형식 등을 기술.
4. **체인 구성**:
   - 사용자 입력을 받아 에이전트가 추론을 통해 데이터를 어떻게 찾을지 결정.
   - 의도에 따라 툴(API)을 호출하는 로직이 삽입됨.
   - 재차 LLM 호출을 통해 최종 정리된 답변을 생성.
5. **메모리 관리**: 대화나 행동이 누적될 때마다 중요 정보 요약, 벡터 DB 삽입 등을 통해 정보가 소실되지 않도록 주의.
6. **결과 및 모니터링**: 에이전트가 생성한 결과물이 목표에 부합하는지 모니터링하고, 필요하다면 프롬프트 및 체인을 개선.

---

## 6. 참고 자료

- [LangChain 공식 문서](https://github.com/hwchase17/langchain)
- [Transformers 라이브러리](https://github.com/huggingface/transformers)
- [OpenAI API 문서](https://platform.openai.com/docs/introduction)

---

## 7. 마치며

LLM 기반 에이전트는 자연어로 명령하고, 시스템이 이를 이해하여 행동을 수행하는 새로운 인터페이스를 제시한다. 프롬프트 엔지니어링, 체인 구성, 툴 연동, 메모리 관리 등 핵심 요소를 잘 조합하면 단순 질의응답 이상의 풍부한 기능을 제공할 수 있다. 앞으로도 다양한 프레임워크와 라이브러리의 등장으로, 에이전트 구현은 점점 더 간단하고 유연해질 것으로 보인다.

## LLM 에이전트를 심화하여 이해하기

LLM을 활용해 에이전트를 만들 때는 단순히 모델을 호출하는 데서 그치지 않고, 프롬프트를 어떻게 구성할지, 모델이 필요한 정보를 어떻게 얻어올지, 외부의 툴(도구)와는 어떻게 연동할지 등을 종합적으로 고려해야 한다. 이 글에서는 보다 심화된 내용들을, 중요하다고 판단되는 순서대로 소개해보겠다.

---

## 1. 프롬프트 활용과 관리

[프롬프트 엔지니어링](https://www.promptingguide.ai/kr)

### 1.1 프롬프트 엔지니어링의 중요성

프롬프트 엔지니어링은 LLM으로부터 원하는 답변을 이끌어내는 핵심 기술이다. 모델의 답변 품질은 어떻게 “질문을 구성”했는지에 따라 크게 달라진다.

- **역할(Role) 지시**: 예를 들어 “너는 전문 상담가처럼 답해줘”라는 식으로 모델의 말투, 시나리오, 지식 범위를 특정해줄 수 있다.
- **목표나 제약사항 명시**: “한 문단 이내로 답변” 혹은 “JavaScript 코드 예시를 꼭 포함해줘”처럼 구체적 요구사항을 기재.
- **적절한 맥락 부여**: 이전 대화나 추가 자료에서 중요한 정보를 발췌해 프롬프트에 첨부하면 모델이 더 정확히 이해한다.

### 1.2 체계적 관리와 버전닝

프로젝트가 커지면 프롬프트가 단계별로 늘어나고 다양해진다. 각 프롬프트마다 목적, 형식, 예시 등을 담은 템플릿을 구성하고 버전 관리를 하는 방식이 유용하다.

- **템플릿화**: 특정 형태(예: YAML, JSON)로 정리해두고, 필요한 파라미터만 바꿔서 동적으로 생성.
- **Prompt Store**: Git 리포지토리나 데이터베이스에 보관해 변경 이력을 추적.
- **Prompt Testing**: 각 프롬프트가 의도대로 작동하는지 자동화된 테스트 케이스를 작성할 수도 있다.

### 1.3 프롬프트의 종류 및 활용

- **system prompt**: 모델이 어떤 역할을 수행할지, 어떤 정보를 참조할지 등을 지시.
- **task prompt**: 특정 작업을 수행하도록 지시하는 프롬프트. 예를 들어, “번역해줘”나 “요약해줘” 등.
- **context prompt**: 대화의 맥락을 유지하기 위한 프롬프트. 이전 대화 내용을 참조해야 할 때 활용.

### 1.4 파라미터의 활용

프롬프트에 파라미터를 삽입해, 동적으로 다양한 상황에 대응할 수 있다.

- **temperature**: 생성된 텍스트의 다양성을 조절하는 파라미터. (0이면 가장 확실한 답변, 1이면 가장 다양한 답변)
- **top_p**: 생성된 텍스트의 확률 분포를 조절하는 파라미터. (0.9 이상이면 다양성이 높아짐)
- **max_Len**: 생성할 텍스트의 최대 길이를 제한하는 파라미터.
- **stop sequence**: 특정 텍스트가 생성되면 생성을 중단하는 파라미터.
- **frequency penalty**: 반복되는 텍스트를 생성하지 않도록 하는 파라미터.
- **presence penalty**: 특정 텍스트가 생성되도록 유도하는 파라미터.

---

## 2. LangChain과 Vector DB 등 외부 툴의 활용

### 2.1 LangChain

[LangChain](https://github.com/hwchase17/langchain)은 LLM 기반 애플리케이션을 쉽고 빠르게 개발할 수 있도록 지원하는 라이브러리다.

- **체인(Chain) 구성**: 여러 LLM 호출(혹은 함수 호출)을 순차 혹은 병렬적으로 연결해, 단계별 논리를 구성.
- **에이전트 구조(Agent)**: LLM이 스스로 툴(API)를 선택하고 호출할 수 있도록 해준다. 예를 들어, “검색 툴로 최신 뉴스를 검색한 뒤 결과를 종합해 요약” 같은 시나리오를 간단히 설계 가능.
- **메모리(Memory)**: 에이전트가 이전 대화나 호출 결과를 기억하도록 지원해, 좀 더 자연스럽고 연속적인 대화가 가능.

### 2.2 Vector DB

Vector DB는 텍스트 임베딩(Embedding)을 인덱싱하고 빠르게 검색하기 위한 데이터베이스다. 대표적으로 Pinecone, Weaviate, Milvus 등이 있다.

- **임베딩 기반 검색**: 텍스트를 벡터(실수 배열)로 변환해 저장해두고, 유사성 검색을 수행한다. 코사인 유사도, 내적 등을 통해 문맥적으로 가장 비슷한 텍스트를 빠르게 찾을 수 있다.
- **RAG(Retrieval-Augmented Generation)**에서 필수: 모델이 답변할 때 필요한 정보를 벡터 DB에서 가져와 참조하는 구조를 만든다.

### 2.3 기타 툴 연동 (toolchain)

- **Third-party API**: 검색 엔진, 계산, 번역, 이메일 송수신 등. LLM이 적절한 시점에 API를 호출해 결과를 받아오면, 더욱 폭넓은 기능의 에이전트를 설계할 수 있다.
- **데이터베이스 연동**: SQL 혹은 NoSQL 기반 DB와 연결해, 모델이 직접 쿼리를 생성하고 테이블에서 필요한 데이터를 획득하도록 할 수 있다.

---

## 3. RAG(Retrieval-Augmented Generation)와 임베딩

### 3.1 RAG의 개념

RAG(Retrieval-Augmented Generation)는 모델이 답변을 생성할 때 외부 지식 소스(주로 Vector DB)를 참조해 보다 풍부한 정보를 바탕으로 응답하도록 만드는 기법이다.

1. **질의(프롬프트) -> 임베딩 변환**
2. **Vector DB 유사성 검색** -> 관련도 높은 문서(혹은 텍스트 조각) 획득
3. **LLM에게 문서 제공 + 질의 내용** -> 응답 생성

### 3.2 임베딩(Embedding)의 이해

임베딩은 텍스트(단어나 문장 등)을 고정된 차원의 벡터로 변환하는 방법이다.

- **특징**: 유사한 의미를 가진 텍스트는 유사한 방향(코사인 유사도 기준)의 벡터로 매핑된다.
- **활용**: 검색, 추천, 클러스터링, 분류 등 NLP 작업 전반에 유용.
- **생성 모델**: OpenAI의 text-embedding-ada-002, Sentence-BERT, FastText 등 다양한 모델이 존재한다.

### 3.3 RAG의 이점

- **최신 정보 및 전문 지식 활용**: LLM이 사전에 학습하지 못한 최신 또는 특정 도메인 정보를 Vector DB로부터 가져와 정확도를 높인다.
- **모델 파라미터 재학습 없이 확장 가능**: 직접 모델을 업데이트하지 않아도, DB에 새로운 텍스트만 추가하면 최신 지식을 반영할 수 있다.

---

## 4. 파인튜닝(Fine-Tuning)

[파인튜닝(Fine-Tuning)이란?](https://wikidocs.net/120208)

파인튜닝이란: 사전 학습된 모델을 특정 도메인이나 태스크에 맞게 추가 학습시키는 기법이다. LLM 기반 에이전트를 만들 때, 파인튜닝을 통해 모델이 특정 도메인에 더 적합한 답변을 생성하도록 할 수 있다.

### 4.1 파인튜닝의 목적

프롬프트만으로 원하는 응답을 얻기 힘들거나, 특정 도메인 태스크 성능을 극대화하고자 할 때 파인튜닝을 고려한다.

- **태스크 전문성 부여**: 예를 들어, 회계 관련 용어를 정확히 인지하고 해석해야 하는 모델이 필요할 때.
- **스타일, 톤 조절**: 특정 어투나 형식으로 답변하도록 학습할 수 있다.

### 4.2 파인튜닝의 절차

1. **데이터 수집**: 원본 데이터(질문-답변 쌍, 문장-레이블 등)를 정제.
2. **포맷팅**: 모델에 맞는 형태(예: JSONL, CSV, TFRecord 등)로 변환.
3. **학습 파라미터 설정**: 학습률, 배치 크기, 에폭 수 등.
4. **학습 실행**: 원하는 프레임워크(TensorFlow, PyTorch 등)나 API(OpenAI의 Fine-tune API 등)로 파인튜닝 진행.
5. **평가 및 검증**: 별도 검증 세트를 통해 성능 측정.
6. **배포 및 유지보수**: 파인튜닝 결과 모델을 배포하고, 필요 시 재학습.

### 4.3 주의할 점

- **오버피팅**: 특정 도메인에 지나치게 과적합하면 범용성이 떨어질 수 있다.
- **데이터 품질**: 파인튜닝에 사용되는 데이터가 부정확하거나 일관성이 없으면, 모델이 잘못 학습될 위험이 있다.

---

## 마무리

LLM 기반 에이전트를 제대로 활용하려면, 단순히 모델만 호출하는 것이 아닌 다양한 기법과 도구가 결합되어야 한다. 프롬프트 엔지니어링으로 모델의 답변 품질을 높이고, LangChain과 Vector DB 등을 사용해 유연하고 강력한 에이전트 구조를 잡을 수 있다. 또한 임베딩을 통한 RAG 기법으로 정보 참조를 강화하고, 필요하다면 파인튜닝을 거쳐 특정 도메인 전문성을 더욱 높일 수 있다.
