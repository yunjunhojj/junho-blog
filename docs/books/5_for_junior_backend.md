# 주니어 백엔드 개발자가 반드시 알아야 할 실무 지식

- 독서 기간 (2025.06.25 ~ ) / 스터디를 통해 진행
- 목적 : JS 기반으로 알고리즘 공부와 더불어 코딩 테스트 준비

## 목차 요약

- 1장 들어가며
- 2장 느려진 서비스, 어디부터 봐야 할까
- 3장 성능을 좌우하는 DB 설계와 쿼리
- 4장 외부 연동이 문제일 때 살펴봐야 할 것들
- 5장 비동기 연동, 언제 어떻게 써야 할까
- 6장 동시성, 데이터가 꼬이기 전에 잡아야 한다
- 7장 IO 병목, 어떻게 해결하지
- 8장 실무에서 꼭 필요한 보안 지식
- 9장 최소한 알고 있어야 할 서버 지식
- 10장 모르면 답답해지는 네트워크 기초
- 11장 자주 쓰는 서버 구조와 설계 패턴

- 부록 A: 처음 해보는 성능 테스트를 위한 기본 정리
- 부록 B: NoSQL 이해하기
- 부록 C: DB로 분산 잠금 구현하기
- 총 356 Page

## 스터디 진행

- 기간 : 6월 25일 부터 진행 ~ 약 2달 예상
- 날짜 : 매주 수요일, 10시부터 진행할 예정
- 한번 스터디때마다 2명이 발표를 하고, 간단한 퀴즈까지 내주시면 감사합니다. (퀴즈는 필수 아님)
  발표시간은 30분 이내로 하는 것이 적당할 듯 하고, 디스코드에서 진행합니다.
- 발표자 이외의 분들도 책을 읽어오면 좋을 것 같아요 (권장)
- 발표자 2명은 제가 랜덤 순서를 정하겠습니다.
- 요약 : 매주 하루, 2명 발표, 둘이 각각 1장(챕터) 발표
- 특이사항 : 짧은 챕터는 한명이 2장을 발표하겠습니다.

## 1장 & 2장

<details>
  <summary>1장 들어가며</summary>

DB 커넥션을 닫아주지 않아서 문제가 생겼던 적, 커넥션 연결 시간 설정을 제대로 해주지 않아서 문제가 생겼던 적을 예시로 들면서 책이 시작합니다. 모두가 할 수 있는 실수들 이제는 안해도될 실수를 안하기 위해 이 책을 읽게 됐습니다.

</details>

<details>
  <summary>2장 느려진 서비스, 어디부터 봐야 할까</summary>

> 서비스가 느려졌을 때 어디부터 점검해야 하는지를 실무 관점에서 풀어낸 챕터. 다양한 성능 정검 포인트를 미리 알아두면 실무에서도 도움이 될 것 입니다.

## 처리량(Throughput)과 응답 시간(Response Time)

- 처리량: 단위 시간 내에 처리 가능한 요청 수
- 응답 시간: 클라이언트 요청 → 응답 완료까지 걸린 시간

```mermaid
flowchart LR
A[클라이언트 요청] --> B[서버 처리]
B --> C[DB 조회 / 캐시 확인]
C --> D[응답 생성]
D --> E[클라이언트 응답]
```

### 응답 시간

**TTFB(Time to First Byte)**

> 클라이언트가 요청을 보낸 후, 서버로부터 첫 번째 바이트를 수신할 때까지 걸린 시간

```
[클라이언트 요청] → [서버 수신] → [서버 처리 시작] → [첫 바이트 전송] ← 이 시점까지의 시간
```

- 포함되는 시간
  - 네트워크 왕복 시간(RTT)
  - 서버의 요청 처리 시작 시간
  - 응답 헤더 및 첫 데이터 생성 시간

**📦 TTLB(Time to Last Byte)**

> 클라이언트가 요청을 보낸 후, 서버 응답의 마지막 바이트까지 모두 수신한 시간

```
[요청 시작] → ... → [첫 바이트 수신] → ... → [마지막 바이트 수신] ← 전체 응답 시간
```

- 포함되는 시간

  - TTFB 전체
  - 전체 응답 본문 전송 시간 (payload의 크기, 전송 속도 영향 받음)

- **Bad** TTFB 높음:
  백엔드에서 API 요청 처리에 2초가 걸림 → 첫 바이트가 2초 뒤에 도착

- **Bad** TTLB 높음:
  서버 응답으로 30MB 이미지 데이터를 전송 중 → 마지막 바이트가 도착하는 데 5초

### 처리량

**RPS (Requests Per Second)**

> 1초당 서버가 처리한 HTTP 요청(Request)의 수

예시 상황

- 프론트엔드가 /api/users 요청을 1초에 100번 보내면 → RPS = 100
- 사용자가 웹페이지 접속 시 HTML, CSS, JS 등 여러 개 요청이 발생 → 요청 수가 많아짐

```mermaid
graph LR
User1 --> Server
User2 --> Server
User3 --> Server
Server --> RPS[요청 처리량: 300 RPS]
```

**TPS (Transactions Per Second)**

> 1초당 처리된 트랜잭션(Transaction)의 수

트랜잭션이란?

- 원자적으로 수행되는 연산 단위. 성공하거나, 전부 실패해야 함 (ACID 원칙)
  보통 DB나 금융 시스템에서 많이 쓰임

예시 상황

- 은행 시스템에서 계좌 이체 100건 처리 → TPS = 100
- 게시판에서 게시물 작성, 수정, 삭제 같은 DB 트랜잭션 수행

```mermaid
flowchart LR
A[API 서버] --> B[DB 트랜잭션 처리] --> C[TPS: 50]
```

## 서버 성능 개선 기초

초기에는 성능 개선할게 없지만, 트래픽이 늘고 데이터가 많이질수록 개선해야할 사항들이 보입니다.
이떄 어디를 봐야할까요

### 병목 지점(Bottleneck) 파악

**병목의 위치는 어떤 종류가 있을까?**

1. 애플리케이션 로직
2. 데이터베이스
3. 외부 API
4. 네트워크
5. 디스크 I/O

```mermaid
graph TD
REQ[요청] --> APP[애플리케이션]
APP --> DB[DB 처리]
APP --> EXT[외부 API]
APP --> FS[파일 시스템]
DB --> RES[응답]
EXT --> RES
FS --> RES
```

🔍 병목 위치에 따라 접근 방식이 달라진다.

### 수직 확장과 수평 확장

| 구분      | 설명                    | 예시                          |
| --------- | ----------------------- | ----------------------------- |
| 수직 확장 | 서버 스펙을 올림        | CPU, RAM 업그레이드           |
| 수평 확장 | 서버 인스턴스 수를 늘림 | 서버를 여러 대 두고 부하 분산 |

```mermaid
graph LR
subgraph 수직 확장
S1[서버 1 - 2CPU → 4CPU]
end


subgraph 수평 확장
  S2[서버 1]
  S3[서버 2]
end
LB[로드 밸런서] --> S2
LB --> S3
```

**수직 확장**

특징

- 기존 인프라 구조를 크게 바꾸지 않아도 됨
- 구현이 단순하고 빠름
- 단일 서버 성능을 극대화하는 접근

사용 시점

- 서버 한 대에서 처리하는 로직이 복잡할 때
- DB, 캐시 등 상태 기반 서비스에 적합 (데이터 공유 이슈 있음)
- 시스템이 단순하고 트래픽이 일정 수준 이하일 때

단점

- 확장 한계가 있음 (물리적 한계)
- 비용 대비 효율이 떨어질 수 있음
- 장애 시 리스크가 큼 (SPOF: 단일 장애점)

**수평확장**

특징

- 고가용성, 탄력성 확보에 유리
- 트래픽 증가에 더 유연하게 대응 가능
- 무중단 배포, Blue-Green, Canary 등과도 잘 어울림

사용 시점

- 사용자 수 급증, 트래픽이 많아진 상황
- 웹 서버, API 서버처럼 무상태(Stateless) 서비스
- 클라우드 환경에서 자동 확장을 적용하고 싶을 때

단점

- 아키텍처 복잡도 증가 (로드밸런서, 세션 공유 등 필요)
- 초기 구축 비용과 관리 부담이 있음

## 커넥션을 관리해보자

- DB와의 연결은 비용이 큼 → 매번 연결/해제 X
- 미리 만들어둔 연결을 재사용
- 커넥션 풀이 없으면? → Too many connections, Connection timeout

```mermaid
sequenceDiagram
Client->>App: DB 요청
App->>Pool: 커넥션 요청
Pool->>DB: 연결 유지
DB-->>App: 결과 응답
App-->>Client: 응답 전달
```

**커넥션 풀 튜닝 포인트**

- 크기: 과하면 자원 낭비, 적으면 병목
- 대기 시간: 커넥션이 풀에 없을 때 기다리는 시간
- 최대 유휴 시간: 일정 시간 이상 사용되지 않으면 제거
- 유효성 검사: 커넥션이 죽었는지 확인
- 최대 유지 시간: 커넥션을 너무 오래 쓰지 않도록

### DB 커넥션 풀

개념

DB와의 연결(Connection)을 미리 여러 개 생성해 풀(Pool)에 저장하고,
요청이 들어올 때마다 이 커넥션을 재사용하는 방식.

왜 필요한가?

- DB 연결은 TCP 핸드셰이크, 인증 등 비용이 큼
- 매 요청마다 커넥션을 생성/해제하면 성능 저하, 커넥션 수 과다 발생

### 커넥션 풀 크기

동시에 유지할 수 있는 DB 커넥션의 최대 수

고려 요소 - 설명

- DB의 max connections: RDS 등에서는 하드 제한 존재
- 서버 수 (App 인스턴스 수): 전체 풀 크기 = 각 인스턴스의 풀 크기 × 인스턴스 수
- 평균 처리 시간: 하나의 커넥션을 점유하는 시간에 따라 다름
- 예상 QPS: 처리량 대비 적절한 커넥션 수 필요

  - 너무 작으면 대기 큐 발생 → 병목
  - 너무 크면 DB 자원 초과 → 장애 발생 가능

### 커넥션 대기 시간

커넥션 풀에 사용 가능한 커넥션이 없을 때, 얼마나 기다릴지 설정하는 시간

API SLA 기준: 응답 보장 시간보다 짧게
사용자 UX 기준: 500ms~1초가 일반적 기준
서버 장애 대비: 무한 대기는 비추천 (적절한 fallback 로직 필요)

대기 시간 초과 시 결과

- 예외 발생 (TimeoutError, AcquireTimeoutError)
- 알람 시스템과 연계하여 이상 징후 탐지 가능

**요약**

- 커넥션 풀 크기 설정 시, 모든 WAS 인스턴스 합산해서 DB의 최대 허용 수 이내로 제한해야 함
- 커넥션 대기 시간은 클라이언트 요청 타임아웃보다 살짝 작게 설정
- 유효성 검사 쿼리(SELECT 1 등) 를 주기적으로 돌려 죽은 커넥션 감지
- 장애 상황 대비, Fallback 처리 로직도 반드시 구성 (e.g. Circuit Breaker)

## 최대 유휴 시간, 유효성 검사, 최대 유지 시간

## 캐시를 활용해보자

**캐시 계층 구조**

```mermaid
graph TD
CLIENT --> APP[서버]
APP --> LOCAL[로컬 캐시 - 메모리]
LOCAL --> REMOTE[리모트 캐시 - Redis]
REMOTE --> DB[DB]
```

**캐시 전략**

| 전략             | 설명                                |
| ---------------- | ----------------------------------- |
| 적중률(Hit Rate) | 캐시에서 원하는 데이터를 찾을 확률  |
| 삭제 규칙        | LRU, LFU, TTL 등                    |
| 캐시 사전 적재   | 사용 가능성 높은 데이터를 미리 저장 |
| 캐시 무효화      | DB 변경 시 캐시 동기화 전략 필요    |

### 서버 캐시

> 서버 측에서 자주 요청되는 데이터나 계산 결과를 임시 저장하여 반복되는 요청에 대해 빠르게 응답할 수 있도록 하는 전략

적용 위치

- DB 조회 결과
- 연산 비용이 큰 API 응답
- 외부 API 호출 결과
- HTML SSR 결과 (예: Next.js getStaticProps)

장점

- DB/서버 부하 감소
- 응답 속도 향상
- 비용 절감 (외부 API 호출 최소화 등)

### 적중률과 삭제 규칙

캐시 적중률 (Cache Hit Ratio): 전체 요청 중 캐시를 통해 응답된 비율

- 높을수록 성능 효율 우수
- 낮으면 캐시 전략이 잘못된 것

삭제(만료) 규칙 – Eviction Policy

- LRU (Least Recently Used): 가장 오래 사용되지 않은 항목 삭제
- LFU (Least Frequently Used): 가장 적게 사용된 항목 삭제
- FIFO: 먼저 들어온 항목부터 삭제
- TTL (Time To Live): 저장된 후 일정 시간이 지나면 삭제

### 로컬 캐시 vs 리모트 캐시

| 항목         | 로컬 캐시 (Local)                      | 리모트 캐시 (Remote)          |
| ------------ | -------------------------------------- | ----------------------------- |
| 저장 위치    | 애플리케이션 메모리                    | 별도 캐시 서버 (Redis 등)     |
| 접근 속도    | 매우 빠름 (ms 이내)                    | 네트워크 따라 다름            |
| 데이터 공유  | 불가능 (서버 간 공유 불가)             | 가능 (여러 서버 간 공유 가능) |
| 장애 시 영향 | 앱 프로세스 죽으면 캐시 유실           | 고가용성 구성 가능            |
| 사용 예시    | 짧은 TTL의 데이터, Config, 사용자 설정 | 사용자 세션, 대량 조회 결과   |

### 캐시 사전 적재

정의

자주 쓰이는 데이터를 미리 캐시에 넣어두는 작업

사용 시점

- 서비스 시작 시 (Warm-up)
- 정기적으로 인기 데이터 업데이트
- 대규모 트래픽 이전 (예: 이벤트 직전)

장점

- Cold Start 이슈 방지
- 초기 사용자 경험 개선

### 캐시 무효화 (Cache Invalidation)

**정의**  
캐시에 저장된 데이터가 더 이상 유효하지 않을 때 **제거하거나 갱신**하는 과정

| 전략                         | 설명                                                    | 사용 예시                        |
| ---------------------------- | ------------------------------------------------------- | -------------------------------- |
| TTL 기반 만료                | 일정 시간이 지나면 자동으로 삭제                        | 뉴스, 상품 정보 등               |
| 수동 무효화                  | API 호출 또는 데이터 변경 시 직접 삭제                  | 게시글 수정 후 `del(post:${id})` |
| 버전 기반 무효화             | key에 버전 정보를 포함해 새 버전 요청 시 이전 캐시 무시 | `post:v1:id=123`                 |
| Write-through / Write-behind | DB 변경 시 캐시를 동기화하는 패턴                       | Redis와 RDB 조합                 |

## 가비지 컬렉터와 메모리 사용

- GC는 예측 불가한 멈춤을 유발 → Full GC는 특히 위험
- 메모리 사용량 분석 필수
  - heap, stack, native, off-heap 등을 구분해 추적
- Java, Node.js 같은 언어는 GC 튜닝이 중요

## 응답 데이터 압축

- gzip, Brotli 압축으로 전송량 줄이기
- 응답 크기 ↓ → 네트워크 시간 ↓

## 정적 자원은 어떻게 효율적으로 보내줄까?

- 이미지, JS, CSS → CDN + 브라우저 캐시 적극 활용
- 정적 파일은 /public, S3, Cloudflare, Fastly 등과 연계

```mermaid
sequenceDiagram
Client->>Browser: 요청
Browser->>CDN: 정적 자원 요청
CDN->>Origin Server: (캐시 없음 시) 요청
Origin Server-->>CDN: 파일 전달
CDN-->>Browser: 캐싱된 자원 전달
```

### 정적 자원과 브라우저 캐시

### 정적 자원과 CDN

## 대기 처리 (Queueing)

- 비동기 처리로 사용자 응답 속도 확보
- 메시지 큐(RabbitMQ, Kafka, SQS) 활용

```mermaid
sequenceDiagram
Client->>App: 요청
App->>Queue: 비동기 메시지 전송
Queue->>Worker: 작업 전달
Worker-->>DB: 데이터 저장
```

## 요약

- 병목을 찾는 것이 우선이다 (무작정 코드 최적화 X)
- 커넥션, 캐시, 압축, GC 등 다양한 레이어에서 최적화 포인트가 존재
- 시스템 전반을 이해하고, 원인을 추론할 수 있는 실력이 중요

</details>
